# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://kedro.readthedocs.io/en/stable/05_data/01_data_catalog.html

_csv: &csv
  type: pandas.CSVDataSet
  save_args:
    index: False

all_euro_data_2000_2023:
  type: PartitionedDataSet
  dataset:
    type: pandas.ExcelDataSet
    load_args:
      sheet_name: null
      engine: null
  path: ./data/01_raw
  filename_suffix: .xls

concatenated_raw_data:
  type: spark.SparkDataSet
  filepath: ./data/02_intermediate/concatenated_raw_data
  file_format: parquet
  load_args:
    header: True
    schema:
      filepath: ./data/01_raw/filtered_schema.json
  save_args:
    sep: '|'
    header: True

filtered_schema:
  type: json.JSONDataSet
  filepath: ./data/01_raw/filtered_schema.json

filtered_dataset_schema:
  type: json.JSONDataSet
  filepath: data/01_raw/filtered_dataset_schema.json

all_league_raw_data:
  type: spark.SparkDataSet
  filepath: ./data/02_intermediate/all_league_raw_data
  file_format: parquet
  load_args:
    header: True
    inferSchema: True
  save_args:
    header: True
    inferSchema: True